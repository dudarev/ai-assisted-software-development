---
title: "Opus 4.6 in Claude Code: effort tuning + agent swarms (Boris Cherny thread)"
source_url: "https://x.com/bcherny/status/2019471487833706769"
captured_at: "2026-02-17T19:49:13+02:00"
distilled_at: "2026-02-17T17:50:46Z"
raw_refs:
  - "[[raw/2026-02-17T194913+0200 - Thread by @bcherny.md]]"
capture_type: twitter_thread
status: draft
agent: codex-cli
model: gpt-5.2
confidence_notes: "Distilled from a short Twitter thread; product claims (e.g., “best model yet”, “1m context window”) are presented as stated without independent verification."
tags: ["claude-code", "agentic-coding", "model-selection", "tooling-ux", "ai-agents"]
---

## Summary

Boris Cherny shares early impressions of **Opus 4.6**, describing it as more agentic, more intelligent, able to run longer, and more careful/exhaustive than prior versions. For **Claude Code**, he highlights a new ability to tune how much the model “thinks” (effort) and indicates he personally keeps effort at maximum. In replies, he confirms an “agent swarm” feature exists, suggests update/install commands for Claude Code, and clarifies that Claude Code does not auto-switch models.

## Topics

- Opus 4.6 impressions: longer-running, more exhaustive/careful
- Claude Code effort tuning via `/model` and `/effort`
- “Agent swarm” confirmation (without details)
- Install/update notes (Homebrew cask, `claude update`)
- Model switching question: “no auto-switch”

## Key points

- **Opus 4.6 is framed as “best yet”** by the author: longer runs, more careful/exhaustive behavior.
- **Effort as a user-controlled knob**: `/model` to tune effort (left/right), and `/effort max` is mentioned as a direct command.
- **Default preference**: the author says he keeps effort at **Max**.
- **Agent swarms**: asked if the “agent swarm thing” is included; the author replies “Yes” (no further explanation in-thread).
- **Install/update**: Homebrew install is suggested (`brew install --cask claude-code`); another reply suggests `claude update`.
- **No auto model switching (per author)**: “The model you choose is the model you get.”

## Concepts / principles

**Effort-latency trade-off as product surface area**

Exposing “effort” explicitly turns a hidden trade-off (speed vs. thoroughness) into a user choice. This can reduce surprise (unexpected long runs) but adds a configuration burden (“annoying, it should decide itself”).

**Longer thinking as a distinct feature**

The author’s emphasis (“runs for longer”, “more exhaustive”, “more careful”) points at a class of improvements that may show up as fewer missed edge cases rather than obvious new capabilities.

## Patterns

- **Manual effort control loop**: pick a baseline effort for daily work → temporarily raise effort for hard/ambiguous tasks → drop effort again for iteration speed.
- **Expectation-setting via explicit commands**: simple, discoverable commands (`/model`, `/effort`) can anchor team norms (“we keep effort at Max”).

## Quotes

> I've been using Opus 4.6 for a bit -- it is our best model yet. It is more agentic, more intelligent, runs for longer, and is more careful and exhaustive.
>
> — @bcherny

> Run /model and arrow left/right to tune effort (less = faster, more = longer thinking & better results).
>
> — @bcherny

> Claude Code does not auto-switch models. The model you choose is the model you get
>
> — @bcherny

## Open questions / follow-ups

- When should “max effort” be the default vs. task-specific escalation?
- What does “agent swarm” mean here (roles, coordination, failure modes, costs)?
- How should teams evaluate “more careful/exhaustive” claims (benchmarks, bug rates, review load)?
- What are the practical constraints of any “1m context window” access in Claude Code (availability, UX, costs)?

## Links

- Source: [https://x.com/bcherny/status/2019471487833706769](https://x.com/bcherny/status/2019471487833706769)

